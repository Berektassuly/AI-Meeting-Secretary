# Whisper → LLaMA → Jira

Интерактивное Streamlit-приложение, которое демонстрирует полный конвейер от аудиозаписи переговоров до создания задач в Jira:

1. загрузка и предпрослушивание аудио или видео;
2. распознавание речи faster-whisper (с VAD и авто-выбором модели CPU/GPU);
3. очистка текста через локальный LLM, совместимый с OpenAI API;
4. извлечение задач (JSON) с автогенерацией меток и нормализацией дедлайнов;
5. отправка задач и комментариев в Jira с учётом приоритетов.

## Возможности

- **Автоопределение железа**: проверка наличия `nvidia-smi` и выбор модели (`WHISPER_MODEL_CUDA`/`WHISPER_MODEL_CPU`) и типа вычислений (`int8_float16` или `int8`).
- **Работа с видео**: при необходимости аудио автоматически извлекается через ffmpeg в PCM16 16 кГц.
- **Автообнаружение LLM**: поддержка OpenAI-совместимых эндпоинтов `/v1/chat/completions` и `/v1/responses`, выбор модели через `LLAMA_MODEL`.
- **Инструменты для PM**: мини-панель метрик по стадиям пайплайна, кнопка «Нормализовать дедлайны», автогенерация меток из summary и удобный редактор задач.
- **Интеграция с Jira**: приоритеты сопоставляются по имени или id, описания формируются в Atlassian doc-формате, поддерживается добавление комментария.

## Требования

- Python 3.11+
- ffmpeg (должен быть доступен в `PATH`)
- Установленные зависимости из `requirements.txt`
- Доступ к локальному/само-хостовому LLM, совместимому с OpenAI API
- Доступ к Jira Cloud или серверу с REST API v3

## Переменные окружения

| Переменная | Описание |
| ---------- | -------- |
| `LLAMA_BASE` | Базовый URL LLM (например, `https://host:port`). Если задано, приложение попытается обнаружить нужный метод и модель. |
| `LLAMA_URL` | Полный URL метода (`/v1/chat/completions` или `/v1/responses`). Имеет приоритет над `LLAMA_BASE`. |
| `LLAMA_MODEL` | ID модели, которую следует использовать (опционально). |
| `LLAMA_API_KEY` | Токен авторизации для LLM (если требуется). |
| `LLAMA_AUTH_HEADER` | Название заголовка авторизации (по умолчанию `Authorization`). |
| `LLAMA_AUTH_SCHEME` | Схема авторизации (по умолчанию `Bearer`). |
| `WHISPER_MODEL_CPU` | Модель faster-whisper для CPU (по умолчанию `small`). |
| `WHISPER_MODEL_CUDA` | Модель faster-whisper для GPU (по умолчанию `medium`). |

Для работы с Jira нужно указать данные в форме на странице:
- URL экземпляра (`https://your-domain.atlassian.net`),
- email пользователя,
- API token,
- ключ проекта.

## Локальный запуск

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
streamlit run app.py
```

После запуска приложение доступно по адресу http://localhost:8501.

## Запуск в Docker

```bash
docker build -t ai-meeting-secretary .
docker run --rm -p 8501:8501 \
  -e LLAMA_BASE=http://llama-host:port \
  -e LLAMA_API_KEY=... \
  ai-meeting-secretary
```

При необходимости пробросьте дополнительные переменные окружения (например, `LLAMA_URL`, `LLAMA_MODEL`).

## Сценарий использования

1. Загрузите аудио или видео файл. Приложение покажет плеер для предпрослушивания.
2. Нажмите «Распознать из аудио». При желании укажите язык распознавания.
3. При успешном распознавании текст появится в редактируемом поле. Можно вручную внести правки.
4. Нажмите «Извлечь задачи», чтобы получить список задач из стенограммы.
5. Отредактируйте задачи, воспользуйтесь кнопкой «Нормализовать дедлайны» или добавьте новую задачу вручную.
6. Заполните форму Jira и нажмите «Создать задачи». В результате отобразятся ссылки на созданные задачи и статистика по ошибкам.

Мини-панель метрик в верхней части страницы показывает длительность каждого этапа пайплайна и количество задач.

## Устранение неполадок

- **ffmpeg не найден** — установите ffmpeg и убедитесь, что его директория есть в `PATH`.
- **LLM endpoint not found** — проверьте значения `LLAMA_BASE`/`LLAMA_URL` и доступность сервера.
- **Транскрипция пустая** — убедитесь, что загружен корректный аудио/видео файл и при необходимости укажите язык явно.
- **Ошибки Jira** — проверьте права доступа, правильность ключа проекта и валидность токена.

